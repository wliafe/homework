{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import mltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCSC(mltools.MachineLearning):\n",
    "\n",
    "    @mltools.MachineLearning.trainer\n",
    "    def train(self, num_epochs):\n",
    "        '''迭代训练'''\n",
    "        for _ in range(num_epochs):\n",
    "            self.timer.start()\n",
    "\n",
    "            # 计算训练集\n",
    "            metric_train = mltools.Accumulator(2)  # 累加器：(train_loss, train_size)\n",
    "            self.model.train()  # 训练模式\n",
    "            for x, y in self.train_iter:\n",
    "                x = self.tokenizer(x)\n",
    "                x = x.to(self.device)  # 转换x\n",
    "                y = y.to(self.device)  # 转换y\n",
    "                y_train = self.model(**x)  # 计算模型\n",
    "                y_train = y_train.logits\n",
    "                train_loss = self.loss(y_train, y)  # 计算训练损失\n",
    "\n",
    "                # 梯度更新\n",
    "                self.optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                metric_train.add(train_loss * y.numel(), y.numel())\n",
    "            self.recorder[0].append(metric_train[0] / metric_train[1])\n",
    "\n",
    "            self.timer.stop()\n",
    "\n",
    "            # 计算验证集\n",
    "            metric_val = mltools.Accumulator(3)  # 累加器：(val_loss, val_acc, val_size)\n",
    "            self.model.eval()  # 验证模式\n",
    "            with torch.no_grad():\n",
    "                for x, y in self.val_iter:\n",
    "                    x = self.tokenizer(x)\n",
    "                    x = x.to(self.device)  # 转换x\n",
    "                    y = y.to(self.device)  # 转换y\n",
    "                    y_val = self.model(**x)  # 计算模型\n",
    "                    y_val = y_val.logits\n",
    "                    val_loss = self.loss(y_val, y)  # 计算验证损失\n",
    "                    val_pred = y_val.argmax(dim=1)  # 计算预测值\n",
    "                    val_acc = (val_pred == y).sum()  # 计算验证准确率\n",
    "                    metric_val.add(val_loss * y.numel(), val_acc, y.numel())\n",
    "            self.recorder[1].append(metric_val[0] / metric_val[2])\n",
    "            self.recorder[2].append(metric_val[1] / metric_val[2])\n",
    "\n",
    "            # 打印输出值\n",
    "            self.logger.info(f'train loss {self.recorder[0][-1]:.3f}, val loss {self.recorder[1][-1]:.3f}, val acc {self.recorder[2][-1]:.3f}, {self.timer.avg():.1f} sec/epoch on {str(self.device)}')\n",
    "            self.animator.show(self.recorder.data)  # 添加损失值\n",
    "        else:\n",
    "            # 打印输出值\n",
    "            self.logger.info(f'train loss {self.recorder[0][-1]:.3f}, val loss {self.recorder[1][-1]:.3f}, val acc {self.recorder[2][-1]:.3f}, {self.timer.avg():.1f} sec/epoch on {str(self.device)}')\n",
    "\n",
    "    @mltools.MachineLearning.tester\n",
    "    def test(self):\n",
    "        '''测试模型'''\n",
    "        metric = mltools.Accumulator(2)  # 累加器：(test_acc, test_size)\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.test_iter:\n",
    "                x = self.tokenizer(x)\n",
    "                x = x.to(self.device)  # 转换x\n",
    "                y = y.to(self.device)  # 转换y\n",
    "                y_test = self.model(**x)  # 计算模型\n",
    "                y_test = y_test.logits\n",
    "                test_pred = y_test.argmax(dim=1)  # 计算准确率\n",
    "                test_acc = (test_pred == y).sum()  # 计算测试准确率\n",
    "                metric.add(test_acc, y.numel())\n",
    "        self.logger.info(f'test acc {metric[0] / metric[1]:.3f}')  # 计算测试准确率并输出\n",
    "\n",
    "    @mltools.MachineLearning.predictor\n",
    "    def predict(self):\n",
    "        '''预测模型'''\n",
    "        x, y = next(iter(self.test_iter))  # 从测试中取一个批量\n",
    "        X = self.tokenizer(x)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        y_pred = self.model(**X)  # 计算模型\n",
    "        y_pred = y_pred.logits\n",
    "        y_pred = y_pred.argmax(dim=1)  # 计算预测\n",
    "        for content, pred, real in zip(x, y_pred, y):\n",
    "            print(f'预测值 {pred}, 真实值 {real}, 数据 {content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397dc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, _ = mltools.chn_senti_corp('../data/ChnSentiCorp_htl_all.csv')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer(text, max_length=200, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-chinese\", num_labels=2)\n",
    "loss = nn.CrossEntropyLoss()  # 设置损失函数\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)  # 设置优化器\n",
    "legend = ['train loss', 'val loss', 'val acc']  # 设置图例\n",
    "device = torch.device('cuda')  # 设置设备\n",
    "ml = BERTCSC(train_iter, val_iter, test_iter, tokenizer=tokenize, model=model, loss=loss, optimizer=optimizer, legend=legend, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345be89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.train(num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aea0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
